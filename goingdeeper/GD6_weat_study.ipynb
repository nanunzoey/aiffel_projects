{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "macro-persian",
   "metadata": {},
   "source": [
    "# 임베딩 내 편향성 알아보기\n",
    "\n",
    "- 언어의 사용 패턴이 담긴 코퍼스는 인간 무의식 속에 감춰진 편향성이 고스란히 드러나는 데이터셋이다.\n",
    "- 언어의 의미를 워드 임베딩에 추상적인 형태로 담을 수 있게 되면서, 그 임베딩 공간에서 편향성을 정량적으로 측정하는 방법론들이 최근 활발히 연구되고 있다.\n",
    "- 대표적인 방법론인 Word Embedding Association Test(WEAT) 기법을 알아보고, 이를 활용해 우리가 학습시킨 Word2Vec 임베딩 내의 편향성을 측정해보자.\n",
    "\n",
    "### 목표\n",
    "\n",
    "1. 데이터의 편향성에 대한 문제의식 갖기\n",
    "2. 임베딩 모델의 편향성을 체크하는 방법 중 하나인 WEAT 알아보기\n",
    "3. WEAT 수식의 의미를 이해하고 구현해보기\n",
    "4. pre-trained model을 불러와서 WEAT score 구해보기\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-headline",
   "metadata": {},
   "source": [
    "## 1. 워드 임베딩의 편향성\n",
    "\n",
    "- ['Man is to Computer Programmer as Woman is to Homemaker? Debiasing World Embeddings'](https://arxiv.org/pdf/1607.06520.pdf) 논문에서 저자는 word embedding을 2차원으로 차원 축소해서 시각화했을 때, 분명히 젠더 중립적인 단어임에도 불구하고 프로그래머, 의사, 엔지니어 등의 단어는 남성 대명사 He에 가깝게, Homemaker, Nurse, Hairdresser 등은 여성 대명사 She에 가깝게 위치하는 것을 보여주었다.\n",
    "- ['Semantics derived automatically from language corpora necessarily contain human biases'](https://arxiv.org/pdf/1608.07187.pdf) 논문은 임베딩 모델의 편향을 측정하는 방식 중 하나로 WEAT를 제안한다.\n",
    "- Science와 Art가 남자와 여자라는 단어와 워드 임베딩 상에서의 거리에 차이가 있는지를 계산하는 것이다.\n",
    "- 이 때 각각의 개념을 대표하는 단어들을 여러 개 골라 단어 set을 만들고, 이에 속한 단어들끼리의 편향성을 전부 계산해서 평균을 살펴보는 방식이다.\n",
    "- 즉 Science를 대표하는 target 단어 셋과 Art를 대표하는 target 단어 셋을 통한 개념축 X와 Y가 있고, Male을 대표하는 attribute 단어 셋과 Female을 대표하는 attribute 단어 셋을 통한 개념축 A, B가 있다고 본다.\n",
    "- 이 아이디어는 심리학의 [IAT(Implicit Association Test)](https://implicit.harvard.edu/implicit/selectatest.html)라는 인지편향성 실험 구조에서 따온 것이다.\n",
    "\n",
    "- WEAT 결과표 예시(아래)\n",
    "    - 파란색은 사람의 편향과 같은 경우, 노란색은 사람의 편향과 반대인 경우\n",
    "    - 대부분이 파란색인 것은 사람이 가진 편향이 코퍼스 데이터에 반영되어 있고, 이것으로 만든 워드 임베딩 모델은 그 편향을 내재할 수밖에 없다는 것을 보여준다.\n",
    "    - 또 워드 임베딩 모델마다 다른 점수가 나오는 것도 자세히 분석해볼 필요가 있다.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/80008411/136647452-9c15cafe-a733-4c2e-b962-8504ef2faba6.png)\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "marked-spoke",
   "metadata": {},
   "source": [
    "## 2. WEAT를 통한 편향성 측정\n",
    "\n",
    "- WEAT 점수 계산식\n",
    "![image](https://user-images.githubusercontent.com/80008411/136647528-a2243a51-8e0f-4d1a-9c9a-3d40b37f5db0.png)\n",
    "\n",
    "- 두 벡터의 유사도 측정을 위해 코사인 유사도를 이용한다.\n",
    "- 코산 유사도 계산식\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "- 위 식에서 $s(w, A, B)$가 의미하는 것은 target에 있는 단어 $w$가 두 attribute 셋에 속한 단어들과의 유사도의 평균 값이 얼마나 차이 나는지를 측정한다.\n",
    "    - 즉, 개별 단어 $w$가 개념축에 대해 가지는 편향성을 계산한 값이다.\n",
    "    - 이는 -2에서 2 사이 값을 가지며, 절대값이 클수록 $w$는 개념축에 대해 편향성을 가진다는 뜻이다.\n",
    "    \n",
    "![image](https://user-images.githubusercontent.com/80008411/136647710-c9b1557f-7d3b-4f0a-bf7a-1d34aebe8b18.png)\n",
    "\n",
    "- 식의 분자는 target X, Y에 속하는 각 단어 x, y들이 개념축 A-B에 대해 가지는 편향성을 각각 평균 내서 뺀 차이이다.\n",
    "- 즉 X에 속하는 단어들과 Y에 속하는 단어들이 A-B 개념축에 대해 가지는 편향성의 정도가 뚜렷이 차이 날수록 이 WEAT score 식의 분자값의 절대값이 커진다.\n",
    "- 이 값을 X, Y에 속하는 모든 단어들이 가지는 편향성 값의 표준 편차로 normalize한 값이 최종 WEAT score가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-arlington",
   "metadata": {},
   "source": [
    "## 3. WEAT 구현하기\n",
    "\n",
    "- 1) 두 개의 target 단어 셋 X, Y와 두 개의 attribute 단어 셋 A, B를 정의한다.\n",
    "    - 이때 두 개의 target 셋의 크기가 같아야 하고, 두 개의 attribute 셋의 크기도 같아야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bottom-former",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "filled-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_X = {\n",
    "    '장미': [4.1, 1.2, -2.4, 0.5, 4.1],\n",
    "    '튤립': [3.1, 0.5, 3.6, 1.7, 5.8],\n",
    "    '백합': [2.9, -1.3, 0.4, 1.1, 3.7],\n",
    "    '데이지': [5.4, 2.5, 4.6, -1.0, 3.6]\n",
    "}\n",
    "target_Y = {\n",
    "    '거미': [-1.5, 0.2, -0.6, -4.6, -5.3],\n",
    "    '모기': [0.4, 0.7, -1.9, -4.5, -2.9],\n",
    "    '파리': [0.9, 1.4, -2.3, -3.9, -4.7],\n",
    "    '메뚜기': [0.7, 0.9, -0.4, -4.1, -3.9]\n",
    "}\n",
    "attribute_A = {\n",
    "    '사랑':[2.8,  4.2, 4.3,  0.3, 5.0],\n",
    "    '행복':[3.8,  3. , -1.2,  4.4, 4.9],\n",
    "    '웃음':[3.7, -0.3,  1.2, -2.5, 3.9]\n",
    "}\n",
    "attribute_B = {\n",
    "    '재난': [-0.2, -2.8, -4.7, -4.3, -4.7],\n",
    "    '고통': [-4.5, -2.1,  -3.8, -3.6, -3.1],\n",
    "    '증오': [-3.6, -3.3, -3.5,  -3.7, -4.4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reduced-territory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.1  1.2 -2.4  0.5  4.1]\n",
      " [ 3.1  0.5  3.6  1.7  5.8]\n",
      " [ 2.9 -1.3  0.4  1.1  3.7]\n",
      " [ 5.4  2.5  4.6 -1.   3.6]]\n",
      "[[-1.5  0.2 -0.6 -4.6 -5.3]\n",
      " [ 0.4  0.7 -1.9 -4.5 -2.9]\n",
      " [ 0.9  1.4 -2.3 -3.9 -4.7]\n",
      " [ 0.7  0.9 -0.4 -4.1 -3.9]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([v for v in target_X.values()])\n",
    "Y = np.array([v for v in target_Y.values()])\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aware-application",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.8  4.2  4.3  0.3  5. ]\n",
      " [ 3.8  3.  -1.2  4.4  4.9]\n",
      " [ 3.7 -0.3  1.2 -2.5  3.9]]\n",
      "[[-0.2 -2.8 -4.7 -4.3 -4.7]\n",
      " [-4.5 -2.1 -3.8 -3.6 -3.1]\n",
      " [-3.6 -3.3 -3.5 -3.7 -4.4]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([v for v in attribute_A.values()])\n",
    "B = np.array([v for v in attribute_B.values()])\n",
    "\n",
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "agricultural-uganda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6457646122337399\n"
     ]
    }
   ],
   "source": [
    "def cos_sim(i, j):\n",
    "    return dot(i, j.T)/(norm(i)*norm(j))\n",
    "\n",
    "def s(w, A, B):\n",
    "    c_a = cos_sim(w, A)\n",
    "    c_b = cos_sim(w, B)\n",
    "    mean_A = np.mean(c_a, axis=-1)\n",
    "    mean_B = np.mean(c_b, axis=-1)\n",
    "    return mean_A - mean_B\n",
    "\n",
    "print(s(target_X['장미'], A, B))\n",
    "# attribute_A에 더 가깝다 (양수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "greek-colorado",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.794002342033094\n"
     ]
    }
   ],
   "source": [
    "print(s(target_Y['거미'], A, B))\n",
    "# attribute_B에 더 가깝다 (음수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "established-making",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29551989 0.51723181 0.26499096 0.50924109]\n",
      "0.397\n"
     ]
    }
   ],
   "source": [
    "print(s(X, A, B))\n",
    "print(round(np.mean(s(X, A, B)), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "opposed-throw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.44713039 -0.28310853 -0.33144878 -0.26030641]\n",
      "-0.33\n"
     ]
    }
   ],
   "source": [
    "print(s(Y, A, B))\n",
    "print(round(np.mean(s(Y, A, B)), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "insured-testing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.932\n"
     ]
    }
   ],
   "source": [
    "def weat_score(X, Y, A, B):\n",
    "    \n",
    "    s_X = s(X, A, B)\n",
    "    s_Y = s(Y, A, B)\n",
    "\n",
    "    mean_X = np.mean(s_X)\n",
    "    mean_Y = np.mean(s_Y)\n",
    "    \n",
    "    std_dev = np.std(np.concatenate([s_X, s_Y], axis=0))\n",
    "    \n",
    "    return  (mean_X-mean_Y)/std_dev\n",
    "\n",
    "print(round(weat_score(X, Y, A, B), 3))\n",
    "# score가 꽤 높게 나옴\n",
    "# 즉 꽃은 유쾌한 단어와 상대적으로 가깝고, 곤충은 불쾌한 단어와 가까움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "continuing-dimension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7febf5ae3a50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화해서 살펴보기\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pc_A = pca.fit_transform(A)\n",
    "pc_B = pca.fit_transform(B)\n",
    "pc_X = pca.fit_transform(X)\n",
    "pc_Y = pca.fit_transform(Y)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pc_A[:,0],pc_A[:,1], c='blue', label='A')\n",
    "ax.scatter(pc_B[:,0],pc_B[:,1], c='red', label='B')\n",
    "ax.scatter(pc_X[:,0],pc_X[:,1], c='skyblue', label='X')\n",
    "ax.scatter(pc_Y[:,0],pc_Y[:,1], c='pink', label='Y')\n",
    "# 파란 점 A와 하늘 점 X가 가깝고\n",
    "# 빨간점 B와 핑크 점 Y가 가깝다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-blackberry",
   "metadata": {},
   "source": [
    "## 4. Pre-trained Word Embedding에 WEAT 적용하기\n",
    "\n",
    "- [GoogleNews-vectors-negative300.bin.gz](https://drive.google.com/u/0/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vital-hunter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 48\r\n",
      "drwxr-xr-x 4 root root  4096 Sep 24 06:28 GD1_text_preprocess\r\n",
      "drwxr-xr-x 5 root root  4096 Sep 28 13:34 GD2_sp_tokenizer\r\n",
      "drwxr-xr-x 4 root root  4096 Sep 30 07:16 GD3_topic_modeling\r\n",
      "drwxr-xr-x 4 root root  4096 Oct  2 10:07 GD4_reuters_classification\r\n",
      "drwxr-xr-x 3 root root  4096 Oct  6 08:48 GD5_word_embedding\r\n",
      "-rw-r--r-- 1 root root 24258 Oct  9 08:30 GD6.ipynb\r\n",
      "drwxr-xr-x 2 root root  4096 Oct  9 08:31 GD6_weat\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/aiffel/aiffel_projects/goingdeeper/GD6_weat\n",
    "!ln -s ~/data/* ~/aiffel/aiffel_projects/goingdeeper/GD6_weat\n",
    "!cd ~/aiffel/aiffel_projects/goingdeeper/GD6_weat\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "quiet-blocking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.7/site-packages (4.0.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "excellent-location",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "data_dir = '~/aiffel/aiffel_projects/goingdeeper/GD6_weat' \n",
    "model_dir = os.path.join(data_dir, 'GoogleNews-vectors-negative300.bin')\n",
    "\n",
    "# 50만개의 단어만 활용합니다. 메모리가 충분하다면 limit 파라미터값을 생략하여 300만개를 모두 활용할 수 있습니다. \n",
    "w2v = KeyedVectors.load_word2vec_format(model_dir, binary=True, limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dress-somewhere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x7febf5a3fe10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "exact-mailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n",
      "300\n",
      "(500000, 300)\n"
     ]
    }
   ],
   "source": [
    "# print(len(w2v.vocab))   # Gensim 3.X 버전까지는 w2v.vocab을 직접 접근할 수 있습니다. \n",
    "print(len(w2v.index_to_key))   # Gensim 4.0부터는 index_to_key를 활용해 vocab size를 알 수 있습니다. \n",
    "print(len(w2v['I']))                    # 혹은 단어를 key로 직접 vector를 얻을 수 있습니다. \n",
    "print(w2v.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tough-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.18798828e-04,  1.60156250e-01,  1.60980225e-03,  2.53906250e-02,\n",
       "        9.91210938e-02, -8.59375000e-02,  3.24218750e-01, -2.17285156e-02,\n",
       "        1.34765625e-01,  1.10351562e-01, -1.04980469e-01, -2.90527344e-02,\n",
       "       -2.38037109e-02, -4.02832031e-02, -3.68652344e-02,  2.32421875e-01,\n",
       "        3.20312500e-01,  1.01074219e-01,  5.83496094e-02, -2.91824341e-04,\n",
       "       -3.29589844e-02,  2.11914062e-01,  4.32128906e-02, -8.59375000e-02,\n",
       "        2.81250000e-01, -1.78222656e-02,  3.79943848e-03, -1.71875000e-01,\n",
       "        2.06054688e-01, -1.85546875e-01,  3.73535156e-02, -1.21459961e-02,\n",
       "        2.04101562e-01, -3.80859375e-02,  3.61328125e-02, -8.15429688e-02,\n",
       "        8.44726562e-02,  9.37500000e-02,  1.44531250e-01,  7.42187500e-02,\n",
       "        2.51953125e-01, -7.91015625e-02,  8.69140625e-02,  1.58691406e-02,\n",
       "        1.09375000e-01, -2.23632812e-01, -5.15747070e-03,  1.68945312e-01,\n",
       "       -1.36718750e-01, -2.51464844e-02, -3.85742188e-02, -1.33056641e-02,\n",
       "        1.38671875e-01,  1.76757812e-01,  1.10351562e-01,  1.51367188e-01,\n",
       "        7.86132812e-02, -1.69921875e-01,  1.20605469e-01, -4.37500000e-01,\n",
       "       -4.32128906e-02,  1.34765625e-01, -3.45703125e-01,  9.13085938e-02,\n",
       "        4.71191406e-02,  9.66796875e-02, -1.61132812e-02, -4.71191406e-02,\n",
       "       -4.68750000e-02,  1.37695312e-01,  9.96093750e-02,  4.49218750e-02,\n",
       "       -2.49023438e-02,  1.58203125e-01, -3.57421875e-01, -1.21093750e-01,\n",
       "        1.15722656e-01,  9.08203125e-02,  1.40625000e-01,  1.60156250e-01,\n",
       "       -4.42504883e-03,  5.34667969e-02,  2.28515625e-01,  1.88476562e-01,\n",
       "       -3.88183594e-02, -2.53906250e-01, -1.74804688e-01,  9.81445312e-02,\n",
       "        1.08642578e-02,  1.41601562e-01,  7.81250000e-03,  1.36718750e-01,\n",
       "       -2.08007812e-01, -3.41796875e-02, -2.50000000e-01,  1.25976562e-01,\n",
       "        1.57226562e-01,  3.31115723e-03, -1.51367188e-01, -6.98242188e-02,\n",
       "       -1.40625000e-01,  2.06054688e-01, -3.54003906e-02,  1.57226562e-01,\n",
       "        5.83496094e-02, -3.58886719e-02,  2.12890625e-01, -1.13769531e-01,\n",
       "        1.41601562e-01, -1.29394531e-02,  9.13085938e-02, -3.95507812e-02,\n",
       "        9.76562500e-02, -2.69775391e-02,  1.30004883e-02, -1.30859375e-01,\n",
       "        3.32031250e-01, -3.53515625e-01, -5.44433594e-02, -2.50244141e-02,\n",
       "       -1.42578125e-01,  6.49414062e-02,  5.54199219e-02, -4.83398438e-02,\n",
       "       -1.12304688e-01, -1.32812500e-01, -6.73828125e-02, -1.41601562e-01,\n",
       "       -2.05078125e-01, -1.29882812e-01, -1.04003906e-01, -8.10546875e-02,\n",
       "       -1.67968750e-01,  1.63085938e-01, -1.13769531e-01, -5.17578125e-02,\n",
       "        7.61718750e-02,  3.59375000e-01,  1.04003906e-01,  3.59375000e-01,\n",
       "       -8.74023438e-02,  6.54296875e-02, -1.09863281e-02, -1.88476562e-01,\n",
       "       -6.59179688e-02,  2.30468750e-01, -2.96875000e-01,  6.59179688e-03,\n",
       "        1.49414062e-01, -1.73828125e-01,  1.31835938e-01,  2.36328125e-01,\n",
       "       -9.22851562e-02,  1.70898438e-01, -1.70898438e-02,  3.12500000e-02,\n",
       "       -3.37219238e-03,  9.66796875e-02, -2.61718750e-01, -1.84326172e-02,\n",
       "       -1.85546875e-01,  1.24023438e-01,  3.00781250e-01,  2.43164062e-01,\n",
       "        3.06640625e-01, -3.28125000e-01, -5.05371094e-02,  1.01562500e-01,\n",
       "        7.86132812e-02, -1.44531250e-01, -1.25976562e-01, -2.41699219e-02,\n",
       "        2.94921875e-01, -1.50390625e-01, -3.97949219e-02,  2.75390625e-01,\n",
       "        1.26953125e-01, -9.86328125e-02, -1.39648438e-01,  2.52685547e-02,\n",
       "       -8.54492188e-02, -1.72119141e-02,  9.17968750e-02,  1.39648438e-01,\n",
       "       -2.39257812e-01, -2.11914062e-01, -2.21679688e-01,  1.53320312e-01,\n",
       "       -1.58691406e-02, -2.00195312e-01, -2.07519531e-02,  3.58886719e-02,\n",
       "       -6.96629286e-07, -2.13867188e-01,  2.00195312e-01, -1.09375000e-01,\n",
       "       -5.15136719e-02,  6.22558594e-02, -3.22265625e-01, -7.86132812e-02,\n",
       "        5.02929688e-02,  7.08007812e-02,  1.20117188e-01, -1.79687500e-01,\n",
       "        1.59179688e-01, -1.02233887e-03, -3.49609375e-01,  1.25000000e-01,\n",
       "        6.44531250e-02,  8.10546875e-02, -3.39355469e-02,  7.42187500e-02,\n",
       "       -3.08837891e-02, -1.38671875e-01, -3.19824219e-02,  1.99218750e-01,\n",
       "        1.25000000e-01,  5.68847656e-02, -1.67968750e-01,  1.30859375e-01,\n",
       "        2.90527344e-02, -1.49536133e-02, -1.39648438e-01,  4.07714844e-02,\n",
       "       -1.05590820e-02, -1.74804688e-01,  2.12890625e-01, -1.41601562e-01,\n",
       "        2.30712891e-02, -3.36914062e-02, -8.78906250e-02, -6.64062500e-02,\n",
       "       -6.93359375e-02, -7.42187500e-02,  7.03125000e-02, -2.01416016e-02,\n",
       "       -1.26953125e-01, -3.63769531e-02,  5.93261719e-02,  1.18164062e-01,\n",
       "       -6.34765625e-03, -7.42187500e-02,  3.19824219e-02,  6.68945312e-02,\n",
       "       -2.27539062e-01,  6.54296875e-02,  1.79443359e-02,  1.46484375e-01,\n",
       "       -5.49316406e-02, -1.15234375e-01, -2.16796875e-01,  8.74023438e-02,\n",
       "        2.61718750e-01,  1.54296875e-01,  6.71386719e-03, -2.78320312e-02,\n",
       "       -4.15039062e-03, -2.09960938e-02, -5.51757812e-02, -9.76562500e-03,\n",
       "       -1.29882812e-01,  1.31835938e-01, -8.42285156e-03,  2.29492188e-01,\n",
       "        1.78710938e-01,  1.94335938e-01,  4.68750000e-02,  2.18505859e-02,\n",
       "       -2.75878906e-02,  1.73828125e-01,  1.33789062e-01,  1.36718750e-01,\n",
       "        3.10546875e-01,  9.39941406e-03,  9.22851562e-02, -2.44140625e-01,\n",
       "       -5.10253906e-02,  7.81250000e-02, -1.43554688e-01,  9.17968750e-02,\n",
       "        2.96630859e-02,  9.46044922e-03, -2.04101562e-01,  1.60156250e-01,\n",
       "        1.43554688e-01, -2.02636719e-02,  2.13623047e-02, -6.98242188e-02,\n",
       "       -3.11279297e-03, -2.52685547e-02, -1.09863281e-01,  1.07910156e-01,\n",
       "       -7.03125000e-02, -1.27929688e-01, -5.07812500e-02,  4.27246094e-02,\n",
       "       -7.32421875e-02, -3.54003906e-02,  8.88671875e-02, -3.02734375e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v['happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "necessary-hotel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('glad', 0.7408890724182129),\n",
       " ('pleased', 0.6632170677185059),\n",
       " ('ecstatic', 0.6626912355422974),\n",
       " ('overjoyed', 0.6599286794662476),\n",
       " ('thrilled', 0.6514049172401428),\n",
       " ('satisfied', 0.6437949538230896),\n",
       " ('proud', 0.636042058467865),\n",
       " ('delighted', 0.627237856388092),\n",
       " ('disappointed', 0.6269949674606323),\n",
       " ('excited', 0.6247665286064148)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['happy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "communist-coaching",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('relatives', 0.6662653088569641),\n",
       " ('familiy', 0.6517067551612854),\n",
       " ('families', 0.6252894997596741),\n",
       " ('siblings', 0.6140849590301514),\n",
       " ('friends', 0.6128394603729248),\n",
       " ('mother', 0.6065612435340881),\n",
       " ('aunt', 0.5811319947242737),\n",
       " ('grandparents', 0.5762072205543518),\n",
       " ('father', 0.5717043876647949),\n",
       " ('Family', 0.5672314763069153)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "labeled-supervisor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('elementary', 0.7868632078170776),\n",
       " ('schools', 0.7411909103393555),\n",
       " ('elementary_schools', 0.6597153544425964),\n",
       " ('kindergarten', 0.6529811024665833),\n",
       " ('eighth_grade', 0.6488089561462402),\n",
       " ('School', 0.6477997303009033),\n",
       " ('teacher', 0.63824063539505),\n",
       " ('students', 0.6301522850990295),\n",
       " ('classroom', 0.6281620264053345),\n",
       " ('Schools', 0.6172096133232117)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['school'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "further-treaty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2624874"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WEAT로 편향성 확인하기\n",
    "target_X = ['science', 'technology', 'physics', 'chemistry', 'Einstein', 'NASA', 'experiment', 'astronomy']\n",
    "target_Y = ['poetry', 'art', 'Shakespeare', 'dance', 'literature', 'novel', 'symphony', 'drama']\n",
    "attribute_A = ['brother', 'father', 'uncle', 'grandfather', 'son', 'he', 'his', 'him']\n",
    "attribute_B = ['sister', 'mother', 'aunt', 'grandmother', 'daughter', 'she', 'hers', 'her']\n",
    "\n",
    "X = np.array([w2v[word] for word in target_X])\n",
    "Y = np.array([w2v[word] for word in target_Y])\n",
    "A = np.array([w2v[word] for word in attribute_A])\n",
    "B = np.array([w2v[word] for word in attribute_B])\n",
    "\n",
    "weat_score(X, Y, A, B)\n",
    "# 과학과 관련된 단어가 남성 관련 단어와 가깝고\n",
    "# 예술 관련 단어가 여성 관련 단어와 가깝다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "subject-detection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6909266"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_X = ['pizza', 'coke', 'hamburger', 'ham', 'ramen', 'icecream', 'candy']\n",
    "target_Y = ['salad', 'fruit', 'vegetable', 'herb', 'root', 'greens', 'wholesome']\n",
    "attribute_A = ['junk', 'canned', 'convenience', 'frozen', 'fast']\n",
    "attribute_B = ['health', 'beneficial', 'good', 'nourishing', 'nutritious']\n",
    "\n",
    "X = np.array([w2v[word] for word in target_X])\n",
    "Y = np.array([w2v[word] for word in target_Y])\n",
    "A = np.array([w2v[word] for word in attribute_A])\n",
    "B = np.array([w2v[word] for word in attribute_B])\n",
    "\n",
    "weat_score(X, Y, A, B)\n",
    "# target_X는 attribute_A와, target_Y는 attribute_B와 가깝다\n",
    "# 단어의 의미를 잘 파악했다고 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "suspected-lincoln",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05137869"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_X = ['pizza', 'coke', 'hamburger', 'ham', 'ramen', 'icecream', 'candy']\n",
    "target_Y = ['salad', 'fruit', 'vegetable', 'herb', 'root', 'greens', 'wholesome']\n",
    "attribute_A = ['book', 'essay', 'dictionary', 'magazine', 'novel']\n",
    "attribute_B = ['news', 'report', 'statement', 'broadcast', 'word']\n",
    "\n",
    "X = np.array([w2v[word] for word in target_X])\n",
    "Y = np.array([w2v[word] for word in target_Y])\n",
    "A = np.array([w2v[word] for word in attribute_A])\n",
    "B = np.array([w2v[word] for word in attribute_B])\n",
    "\n",
    "weat_score(X, Y, A, B)\n",
    "# 0에 가깝게 나타남\n",
    "# 유사하다고 보기 어렵다는 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-sharing",
   "metadata": {},
   "source": [
    "## 5. 직접 워드 임베딩을 만들어서 WEAT 적용하기\n",
    "\n",
    "- 1) 형태소 분석기를 이용해 명사 추출하기\n",
    "- 2) 추출된 단어들로 임베딩 모델 만들기\n",
    "- 3) TF-IDF로 해당 데이터를 가장 잘 표현하는 단어 셋 만들기\n",
    "- 4) 임베딩 모델과 단어 셋으로 WEAT score 구하기\n",
    "\n",
    "- 데이터셋: [synopsis.zip](https://d3s0tskafalll9.cloudfront.net/media/documents/synopsis.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sufficient-blair",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-09 08:45:46--  https://aiffelstaticprd.blob.core.windows.net/media/documents/synopsis.zip\n",
      "Resolving aiffelstaticprd.blob.core.windows.net (aiffelstaticprd.blob.core.windows.net)... 52.239.148.4\n",
      "Connecting to aiffelstaticprd.blob.core.windows.net (aiffelstaticprd.blob.core.windows.net)|52.239.148.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18399462 (18M) [application/x-zip-compressed]\n",
      "Saving to: ‘synopsis.zip’\n",
      "\n",
      "synopsis.zip        100%[===================>]  17.55M  6.02MB/s    in 2.9s    \n",
      "\n",
      "2021-10-09 08:45:50 (6.02 MB/s) - ‘synopsis.zip’ saved [18399462/18399462]\n",
      "\n",
      "Archive:  synopsis.zip\n",
      "  inflating: synopsis.txt            \n",
      "  inflating: synopsis_SF.txt         \n",
      "  inflating: synopsis_action.txt     \n",
      "  inflating: synopsis_adult.txt      \n",
      "  inflating: synopsis_adventure.txt  \n",
      "  inflating: synopsis_animation.txt  \n",
      "  inflating: synopsis_art.txt        \n",
      "  inflating: synopsis_comedy.txt     \n",
      "  inflating: synopsis_crime.txt      \n",
      "  inflating: synopsis_documentary.txt  \n",
      "  inflating: synopsis_drama.txt      \n",
      "  inflating: synopsis_etc.txt        \n",
      "  inflating: synopsis_family.txt     \n",
      "  inflating: synopsis_fantasy.txt    \n",
      "  inflating: synopsis_gen.txt        \n",
      "  inflating: synopsis_historical.txt  \n",
      "  inflating: synopsis_horror.txt     \n",
      "  inflating: synopsis_musical.txt    \n",
      "  inflating: synopsis_mystery.txt    \n",
      "  inflating: synopsis_romance.txt    \n",
      "  inflating: synopsis_show.txt       \n",
      "  inflating: synopsis_thriller.txt   \n",
      "  inflating: synopsis_war.txt        \n",
      "  inflating: synopsis_western.txt    \n"
     ]
    }
   ],
   "source": [
    "!wget https://aiffelstaticprd.blob.core.windows.net/media/documents/synopsis.zip\n",
    "!mv synopsis.zip ~/aiffel/aiffel_projects/goingdeeper/GD6_weat\n",
    "!cd ~/aiffel/aiffel_projects/goingdeeper/GD6_weat && unzip synopsis.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "guilty-colonial",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in /opt/conda/lib/python3.7/site-packages (0.5.2)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (3.10.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (1.2.1)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from konlpy) (0.4.4)\n",
      "Requirement already satisfied: numpy>=1.6 in /opt/conda/lib/python3.7/site-packages (from konlpy) (1.19.5)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (4.6.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (4.6.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /opt/conda/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (2.25.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.26.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "superior-fountain",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사운드 엔지니어 상우(유지태 분)는 치매에 걸린 할머니(백성희 분)와\n",
      " 젊은 시절 상처한 한 아버지(박인환 분), 고모(신신애 분)와 함께 살고 있다.\n",
      " 어느 겨울 그는 지방 방송국 라디오 PD 은수(이영애 분)를 만난다.\n",
      " 자연의 소리를 채집해 틀어주는 라디오 프로그램을 준비하는 은수는 상우와 녹음 여행을 떠난다.\n",
      " 자연스레 가까워지는 두 사람은 어느 날, 은수의 아파트에서 밤을 보낸다.\n",
      " 너무 쉽게 사랑에 빠진 두 사람... 상우는 주체할 수 없을 정도로 그녀에게 빨려든다.\n",
      " 그러나 겨울에 만난 두 사람의 관계는 봄을 지나 여름을 맞이하면서 삐걱거린다.\n",
      " 이혼 경험이 있는 은수는 상우에게 결혼할 생각이 없다며 부담스러운 표정을 내비친다.\n",
      " \"어떻게 사랑이 변하니?...\"라고 묻는 상우에게 은수는 그저 \"헤어져\" 라고 단호하게 말한다.\n",
      " 영원히 변할 것 같지 않던 사랑이 변하고, 그 사실을 받아들이지 못하는 상우는 어찌 할 바를 모른다.\n",
      " 은수를 잊지 못하는 상우는 미련과 집착의 감정을 이기지 못하고 서울과 강릉을 오간다.\n",
      "유사 이래 연령, 성별, 빈부의 차이와 정치적인 입장을 불문하고 일거에 국민을 통합해 온 '애국심'이라는 성역에 일침을 가하는 다큐멘터리. 재작년 전국 민족민주 유가족협의회의 장기농성을 다룬 인상적인 다큐멘터리 <민들레>를 만들었던 독립영화집단 '빨간 눈사람'이 우리 사회 구석구석을 발빠르게 돌아다니며 애국심과 민족주의가 강요되는 현장을 발굴하여 카메라에 담았다. 박홍 서강대 명예총장, 이도형 '한국논단' 발행인, 축구해설자 신문선, 홍세화, 박노해 등 사회 각계의 '스타'들이 등장해 저마다의 확고한 신념을 성토한다. 감독 이경순과 최하동하는 이 작품을 위해 3년간 백여 명을 인터뷰했다고 한다. 2001 올해의 독립영화상 수상.\n",
      " 민족과 국가란 공동체에서 부단히 권력과 부를 얻는 자, 나아가 민족과 국가란 공동체에서 얻은 신분과 부귀를 영원히 그의 자손에게 대물림하려는 자, 그래서 민족과 국가란 공동체를 부단히 유지해야만 하는 자, 따라서 민족과 국가란 공동체의 당위성과 개인의 가치를 초월하는 그 존엄성을 끝도 없이 창조하고 되뇌어야 하는 자, 종국에는 민족과 국가란 공동체에 속해 있다고 태내에서부터 세뇌된 모든 이들의 삶과 행동에서 영원히 자기복제되는 순환의 고리, 영생하는 애국의 원동력은 그 순환의 골에서 온다.\n",
      "엽기적인 살인사건이 발생한 장소를 관광하는 투어팀. 그 팀에서 관광객들은 살인사건과 관련하여 히스테리컬한 반응을 보이는데 과연 이들의 정체는? (Tourists see whrer a murder take place. They respond hysterically to the murder…what are they?)\n",
      " 제46회 발라돌리드 국제영화제 (2001, 스페인)\n",
      "착하지만 엉뚱한 태희(배두나 분), 예쁜 깍쟁이 혜주(이요원 분), 그림을 잘 그리는 지영(옥지영 분), 명랑한 쌍둥이 비류(이은실 분)와 온조(이은주 분)는 단짝친구들. 늘 함께였던 그들이지만 스무 살이 되면서 길이 달라진다. 증권회사에 입사한 혜주는 성공한 커리어우먼의 야심을 키우고 미술에 재능이 있는 지영은 유학을 꿈꾼다. 한편 태희는 봉사활동에서 알게 된 뇌성마비 시인을 좋아하는데...\n",
      "  어느 날 지영이 길 잃은 새끼 고양이 티티를 만남면서 스무 살 그녀들의 삶에 고양이 한 마리가 끼어들게 된다. 혼자 있길 좋아하고, 쉽게 마음을 열지 않는 신비로운 동물 고양이. 고양이를 닮은 스무 살 그녀들. 고양이 티티와 함께 한 시간동안 삶은 예상못한 방향으로 흘러가지만 마침내 그녀들만의 해결책을 찾게 되는데... 사랑스런 몽상가 태희, 아름다운 야심가 혜주, 신비로운 아웃사이더 지영. 마지막으로 고양이를 부탁받은 사람은 누구일까?\n",
      "인도 등 아시아 식민지에 처음 발을 디딘 뒤 여행하고 “경영”한 이들은 과연 누구였을까? 과거의 이미지들은, 이민과 인종 문제, ‘오리엔탈리즘’이 격렬히 충돌하고 있는 현재와 강력하게 공명한다.\n",
      " [제19회 인디다큐페스티발]\n",
      "홀로 살아가는 미국 할머니와 한국 할머니의 이야기. 공원에서 가끔 마주치게 되는 그들은 비록 언어 소통의 어려움을 겪지만 시간이 흘러감에 따라 서로 가까워져 그들의 외로움과 우정을 공유하게 된다. 겨울이 지나고 봄이 왔을 때 길가의 민들레 홀씨는 삶의 이치를 말해주듯 한 할머니의 주위를 맴돈다. (Two elderly widows, an American and a Korean, frequent the same park in Philadelphia and attempt a friendship, though the Korean widow speaks no English. Driven by loneliness and a spark of hope, they persevere within the limits of body language, and the outcome poses a question of life as fundamental as a flower.)\n"
     ]
    }
   ],
   "source": [
    "with open(os.getenv('HOME')+'/aiffel/aiffel_projects/goingdeeper/GD6_weat/synopsis.txt', 'r') as file:\n",
    "    for i in range(20):\n",
    "        print(file.readline(), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-release",
   "metadata": {},
   "source": [
    "#### 1) 형태소 분석기를 이용해 명사 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "proper-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "tokenized = []\n",
    "\n",
    "with open(os.getenv('HOME')+'/aiffel/aiffel_projects/goingdeeper/GD6_weat/synopsis.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        \n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in ['Noun']:\n",
    "                res.append(w[0])\n",
    "            tokenized.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "further-expansion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3168454\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-albert",
   "metadata": {},
   "source": [
    "#### 2) 추출된 결과로 임베딩 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "crude-company",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('이야기', 0.6233843564987183),\n",
       " ('작품', 0.5727538466453552),\n",
       " ('픽션', 0.5296003222465515),\n",
       " ('접점', 0.5202867388725281),\n",
       " ('영화로', 0.5183959603309631),\n",
       " ('논픽션', 0.4999814033508301),\n",
       " ('감독', 0.4907528758049011),\n",
       " ('절제', 0.49023956060409546),\n",
       " ('실존', 0.4902290105819702),\n",
       " ('실재', 0.48447084426879883)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# tokenized에 담긴 데이터를 가지고 나만의 Word2Vec을 생성합니다. (Gensim 4.0 기준)\n",
    "model = Word2Vec(tokenized, vector_size=100, window=5, min_count=3, sg=0)  \n",
    "model.wv.most_similar(positive=['영화'])\n",
    "\n",
    "# Gensim 3.X 에서는 아래와 같이 생성합니다. \n",
    "# model = Word2Vec(tokenized, size=100, window=5, min_count=3, sg=0)  \n",
    "# model.most_similar(positive=['영화'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bronze-analyst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('자신', 0.6421274542808533),\n",
       " ('그녀', 0.6392653584480286),\n",
       " ('그', 0.5937655568122864),\n",
       " ('것', 0.5801700949668884),\n",
       " ('아지만', 0.5726699233055115),\n",
       " ('소라치', 0.57231605052948),\n",
       " ('관현악', 0.5616066455841064),\n",
       " ('시작', 0.5560080409049988),\n",
       " ('친구', 0.5476680994033813),\n",
       " ('기사철십자훈장', 0.5367093086242676)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['사랑'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "oriented-adult",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('공연', 0.5264928340911865),\n",
       " ('콜렉티브', 0.5262086391448975),\n",
       " ('뮤지컬', 0.5106148719787598),\n",
       " ('이인근', 0.5048108100891113),\n",
       " ('권은영', 0.5007545948028564),\n",
       " ('영화감독', 0.4917135536670685),\n",
       " ('멜로드라마', 0.48778069019317627),\n",
       " ('보집', 0.48620110750198364),\n",
       " ('군더더기', 0.48384299874305725),\n",
       " ('제작', 0.4615655243396759)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['연극'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-cambodia",
   "metadata": {},
   "source": [
    "#### 3) TF-IDF 로 해당 데이터를 가장 잘 표현하는 단어 셋 만들기\n",
    "\n",
    "- 예술 영화와 상업 영화라는 구분을 target으로 삼고, 드라마 장르와 액션 장르라는 구분을 attribute으로 삼아서 WEAT score를 계산해보자.\n",
    "- 즉 드마라 장르는 예술영화 성격이 강하고, 액션 장르는 상업 영화 성격이 강할 것이라는 편향성이 워드 임베딩 상에 얼마나 나타나고 있는지 측정해보는 것.\n",
    "- 영화 구분\n",
    "    - synopsis_art.txt : 예술영화\n",
    "    - synopsis_gen.txt : 일반영화(상업영화)\n",
    "    - 그 외는 독립영화 등으로 분류됩니다.\n",
    "- 장르 구분\n",
    "    - synopsis_SF.txt: SF\n",
    "    - synopsis_가족.txt: 가족\n",
    "    - synopsis_공연.txt: 공연\n",
    "    - synopsis_공포(호러).txt: 공포(호러)\n",
    "    - synopsis_기타.txt: 기타\n",
    "    - synopsis_다큐멘터리.txt: 다큐멘터리\n",
    "    - synopsis_드라마.txt: 드라마\n",
    "    - synopsis_멜로로맨스.txt: 멜로로맨스\n",
    "    - synopsis_뮤지컬.txt: 뮤지컬\n",
    "    - synopsis_미스터리.txt: 미스터리\n",
    "    - synopsis_범죄.txt: 범죄\n",
    "    - synopsis_사극.txt: 사극\n",
    "    - synopsis_서부극(웨스턴).txt: 서부극(웨스턴)\n",
    "    - synopsis_성인물(에로).txt: 성인물(에로)\n",
    "    - synopsis_스릴러.txt: 스릴러\n",
    "    - synopsis_애니메이션.txt: 애니메이션\n",
    "    - synopsis_액션.txt: 액션\n",
    "    - synopsis_어드벤처.txt: 어드벤처\n",
    "    - synopsis_전쟁.txt: 전쟁\n",
    "    - synopsis_코미디.txt: 코미디\n",
    "    - synopsis_판타지.txt: 판타지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "palestinian-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "art_txt = 'synopsis_art.txt'\n",
    "gen_txt = 'synopsis_gen.txt'\n",
    "\n",
    "def read_token(file_name):\n",
    "    okt = Okt()\n",
    "    result = []\n",
    "    \n",
    "    with open(os.getenv('HOME') + '/aiffel/aiffel_projects/goingdeeper/GD6_weat/' + file_name, 'r') as fread:\n",
    "        print(file_name, '파일을 읽고 있습니다.')\n",
    "        while True:\n",
    "            line = fread.readline()\n",
    "            if not line: break\n",
    "            tokenlist = okt.pos(line, stem=True, norm=True)\n",
    "            \n",
    "            for word in tokenlist:\n",
    "                if word[1] in ['Noun']:\n",
    "                    result.append((word[0]))\n",
    "        return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "manufactured-basement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synopsis_art.txt 파일을 읽고 있습니다.\n",
      "synopsis_gen.txt 파일을 읽고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 2개의 파일을 처리하는데 10분 가량 걸립니다. \n",
    "art = read_token(art_txt)\n",
    "gen = read_token(gen_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "political-assets",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "champion-sally",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 41082)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform([art, gen])\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "controlling-freeze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23976\n",
      "영화\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_['영화'])\n",
    "print(vectorizer.get_feature_names()[23976])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "configured-rebound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예술영화를 대표하는 단어들:\n",
      "그녀, 자신, 시작, 위해, 사랑, 사람, 영화, 친구, 남자, 가족, 이야기, 마을, 사건, 마음, 세상, 아버지, 아이, 엄마, 모든, 여자, 대한, 서로, 과연, 다시, 시간, 아들, 소녀, 아내, 다른, 사이, 영화제, 세계, 사실, 하나, 점점, 남편, 감독, 여행, 인생, 발견, 모두, 순간, 우리, 가장, 마지막, 생활, 아빠, 모습, 통해, 죽음, 기억, 비밀, 학교, 음악, 한편, 소년, 생각, 도시, 명의, 사고, 결혼, 전쟁, 때문, 위기, 이제, 최고, 이자, 과거, 일상, 경찰, 상황, 간다, 미국, 결심, 운명, 현실, 관계, 지금, 단편, 여인, 하루, 이름, 이후, 준비, 인간, 감정, 만난, 국제, 처음, 충격, 살인, 누구, 동안, 존재, 그린, 어머니, 연인, 계속, 동생, 작품, \n",
      "\n",
      "일반영화를 대표하는 단어들:\n",
      "자신, 그녀, 영화제, 위해, 사람, 시작, 국제, 영화, 친구, 사랑, 남자, 이야기, 대한, 서울, 여자, 사건, 남편, 아이, 가족, 아버지, 다른, 마을, 시간, 엄마, 아들, 모든, 단편, 마음, 사실, 다시, 세계, 모습, 작품, 통해, 생각, 서로, 세상, 발견, 감독, 아내, 관계, 소녀, 사이, 하나, 우리, 애니메이션, 때문, 여성, 죽음, 과연, 점점, 인간, 생활, 한편, 결혼, 상황, 모두, 기억, 명의, 소년, 여행, 가장, 간다, 순간, 이제, 도시, 비밀, 학교, 과거, 가지, 이자, 경찰, 마지막, 미국, 동안, 전쟁, 주인공, 대해, 존재, 현실, 연출, 사고, 살인, 일상, 어머니, 계속, 사회, 인생, 다큐멘터리, 부문, 섹스, 최고, 바로, 동생, 의도, 하루, 위기, 계획, 정체, 한국, "
     ]
    }
   ],
   "source": [
    "m1 = X[0].tocoo()   # art를 TF-IDF로 표현한 sparse matrix를 가져옵니다. \n",
    "m2 = X[1].tocoo()   # gen을 TF-IDF로 표현한 sparse matrix를 가져옵니다. \n",
    "\n",
    "w1 = [[i, j] for i, j in zip(m1.col, m1.data)]\n",
    "w2 = [[i, j] for i, j in zip(m2.col, m2.data)]\n",
    "\n",
    "w1.sort(key=lambda x: x[1], reverse=True)   #art를 구성하는 단어들을 TF-IDF가 높은 순으로 정렬합니다. \n",
    "w2.sort(key=lambda x: x[1], reverse=True)   #gen을 구성하는 단어들을 TF-IDF가 높은 순으로 정렬합니다. \n",
    "\n",
    "print('예술영화를 대표하는 단어들:')\n",
    "for i in range(100):\n",
    "    print(vectorizer.get_feature_names()[w1[i][0]], end=', ')\n",
    "\n",
    "print('\\n')\n",
    "    \n",
    "print('일반영화를 대표하는 단어들:')\n",
    "for i in range(100):\n",
    "    print(vectorizer.get_feature_names()[w2[i][0]], end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "pharmaceutical-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 단어 셋이 중복되지 않도록 중복 단어는 제외하고\n",
    "# 상위 n개의 단어를 추출\n",
    "n = 15\n",
    "w1_, w2_ = [], []\n",
    "for i in range(100):\n",
    "    w1_.append(vectorizer.get_feature_names()[w1[i][0]])\n",
    "    w2_.append(vectorizer.get_feature_names()[w2[i][0]])\n",
    "\n",
    "# w1에만 있고 w2에는 없는, 예술영화를 잘 대표하는 단어를 15개 추출한다.\n",
    "target_art, target_gen = [], []\n",
    "for i in range(100):\n",
    "    if (w1_[i] not in w2_) and (w1_[i] in model.wv): target_art.append(w1_[i])\n",
    "    if len(target_art) == n: break \n",
    "\n",
    "# w2에만 있고 w1에는 없는, 일반영화를 잘 대표하는 단어를 15개 추출한다.\n",
    "for i in range(100):\n",
    "    if (w2_[i] not in w1_) and (w2_[i] in model.wv): target_gen.append(w2_[i])\n",
    "    if len(target_gen) == n: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "secure-bhutan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['아빠', '음악', '결심', '운명', '지금', '여인', '이름', '이후', '준비', '감정', '만난', '처음', '충격', '누구', '그린']\n"
     ]
    }
   ],
   "source": [
    "# 추출된 단어 보기\n",
    "print(target_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "creative-closure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['서울', '애니메이션', '여성', '가지', '주인공', '대해', '연출', '사회', '다큐멘터리', '부문', '섹스', '바로', '의도', '계획', '정체']\n"
     ]
    }
   ],
   "source": [
    "print(target_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "assisted-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 장르별 대표 단어 추출\n",
    "genre_txt = ['synopsis_drama.txt', 'synopsis_romance.txt', 'synopsis_action.txt', 'synopsis_comedy.txt', 'synopsis_war.txt', 'synopsis_horror.txt']\n",
    "genre_name = ['드라마', '멜로로맨스', '액션', '코미디', '전쟁', '공포(호러)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "deadly-landscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synopsis_drama.txt 파일을 읽고 있습니다.\n",
      "synopsis_romance.txt 파일을 읽고 있습니다.\n",
      "synopsis_action.txt 파일을 읽고 있습니다.\n",
      "synopsis_comedy.txt 파일을 읽고 있습니다.\n",
      "synopsis_war.txt 파일을 읽고 있습니다.\n",
      "synopsis_horror.txt 파일을 읽고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 약 10분정도 걸립니다.\n",
    "genre = []\n",
    "for file_name in genre_txt:\n",
    "    genre.append(read_token(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "neural-turner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 33151)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(genre)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "forced-roots",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "드라마: 자신, 영화제, 그녀, 사람, 사랑, 위해, 영화, 시작, 국제, 남자, 친구, 이야기, 여자, 아버지, 엄마, \n",
      "멜로로맨스: 그녀, 사랑, 자신, 시작, 남자, 남편, 여자, 사람, 친구, 위해, 마음, 섹스, 결혼, 서로, 아내, \n",
      "액션: 위해, 자신, 시작, 조직, 사건, 사람, 그녀, 경찰, 전쟁, 친구, 모든, 목숨, 사실, 세계, 가족, \n",
      "코미디: 그녀, 자신, 시작, 위해, 사랑, 사람, 친구, 영화, 남자, 여자, 영화제, 가족, 과연, 마을, 사건, \n",
      "전쟁: 전쟁, 위해, 전투, 시작, 작전, 독일군, 부대, 독일, 윈터스, 자신, 사람, 공격, 임무, 연합군, 병사, \n",
      "공포(호러): 시작, 위해, 사람, 자신, 친구, 그녀, 사건, 공포, 발견, 죽음, 마을, 남자, 가족, 영화, 하나, \n"
     ]
    }
   ],
   "source": [
    "m = [X[i].tocoo() for i in range(X.shape[0])]\n",
    "\n",
    "w = [[[i, j] for i, j in zip(mm.col, mm.data)] for mm in m]\n",
    "\n",
    "for i in range(len(w)):\n",
    "    w[i].sort(key=lambda x: x[1], reverse=True)\n",
    "attributes = []\n",
    "for i in range(len(w)):\n",
    "    print(genre_name[i], end=': ')\n",
    "    attr = []\n",
    "    j = 0\n",
    "    while (len(attr) < 15):\n",
    "        if vectorizer.get_feature_names()[w[i][j][0]] in model.wv:\n",
    "            attr.append(vectorizer.get_feature_names()[w[i][j][0]])\n",
    "            print(vectorizer.get_feature_names()[w[i][j][0]], end=', ')\n",
    "        j += 1\n",
    "    attributes.append(attr)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-commission",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
