{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "F31_bigdata_ecosystem.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BGCYHXffit8"
      },
      "source": [
        "# 빅데이터 생태계\n",
        "\n",
        "## 목표\n",
        "\n",
        "1. 하둡과 스파크의 에코시스템을 통해 빅데이터를 구성하는 기술 이해하기\n",
        "2. 스파크의 개요와 특징에 대해 알아보고, PySpark를 이용해 빅데이터 툴을 다뤄보자.\n",
        "\n",
        "## 목차\n",
        "\n",
        "1. 빅데이터 양대 산맥: Hadoop과 Spark\n",
        "2. Spark 소개\n",
        "- Spark 데이터 처리: RDD\n",
        "- RDD 생성과 동작\n",
        "- PySpark 설치\n",
        "- SparkContext를 통한 스파크 초기화\n",
        "3. Spark 실습\n",
        "- RDD Creation\n",
        "- RDD Operation 1) Transformations\n",
        "- RDD Operation 2) Actions\n",
        "- RDD Operation 3) 실습: MapReduce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85jPemvUgMX7"
      },
      "source": [
        "# 1. 빅데이터 연대기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI9A0mxUiWEX"
      },
      "source": [
        "## 1.1 2003년: GFS(Google File System)\n",
        "\n",
        "- 제일 처음으로 발표된 빅데이터용 새로운 파일 시스템\n",
        "- 시스템 고장을 효과적으로 처리할 수 있게 복제가 용이하고, 분산 처리에 적합"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlSKVs6jirc8"
      },
      "source": [
        "## 1.2 2004년: 맵리듀스\n",
        "\n",
        "- MapReduce on Simplified Data Processing on Large Clusters\n",
        "- 구글이 발표한 분산 처리 환경에 맞는 프로그래밍 모델\n",
        "- 데이터 관련 작업을 map 함수와 reduce 함수의 2가지 작업으로 나눠 처리\n",
        "- map 함수는 key-value 쌍을 처리해 중간 key-value 쌍을 생성\n",
        "- reduce 함수는 동일한 key와 연관된 모든 중간 값들을 병합"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXwxJ49Ak4Ev"
      },
      "source": [
        "## 1.3 2004-2005년: NDFS Project\n",
        "\n",
        "- 아파치 재단은 검색 엔진의 효과적인 분산 처리를 위해 NDFS(Nutch Distributed File System)이라는 프로젝트를 시작\n",
        "- Nutch는 엘라스틱 서치라는 검색 엔진의 전신 소프트웨어"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efaynMjXk4A2"
      },
      "source": [
        "## 1.4 2006-2007년: 아파치 하둡\n",
        "\n",
        "- 아파치 재단은 맵리듀스와 GFS 개념을 더 보완해 하둡이라는 빅데이터용 오픈 소스 프로젝트를 시작\n",
        "- 이렇게 만들어진 것이 하둡 1.0이며, 그 핵심 기술은 HDFS와 맵리듀스이다. 이는 현재 빅데이터의 근간이 되는 기술들이다.\n",
        "- [빅데이터 시대를 열다, 하둡을 창시한 더그 커팅](https://brunch.co.kr/@hvnpoet/98)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykyd92rVk390"
      },
      "source": [
        "## 1.5 2007-2008년: 폭발적 성장\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/80008411/144400040-9bce45bb-02b8-4389-b477-43033f31ac56.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUEiyU4Yk369"
      },
      "source": [
        "## 1.6 2009-2013년: Apache Spark\n",
        "\n",
        "- 하둡의 단점: 하드디스크에 파일을 처리하기 때문에, 고속으로 데이터를 처리할 때 메모리에 올려서 처리해야 할 때가 있다는 것\n",
        "- 이러한 니즈가 늘면서 메모리 기반으로 데이터를 처리하는 스파크가 등장\n",
        "- 하둡과 똑같이 맵리듀스 개념을 사용하지만 데이터 처리 방법과 task 정리 방법을 개선해 RDD(Resilient Distributed Dataset)을 이용\n",
        "- [논문: Resilient Distributed Datasets: A Fault-Tolerant Abstraction forIn-Memory Cluster Computing](https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf)\n",
        "- [Spark: Cluster Computing with Working Sets](https://www.usenix.org/legacy/event/hotcloud10/tech/full_papers/Zaharia.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUBcYjJynChI"
      },
      "source": [
        "## 1.7 2014-2020년: Databricks와 Apache Spark\n",
        "\n",
        "- 데이터브릭스는 마태 자하리아가 설립한 스타트업이며, 스파크 관련 데이터 분석 및 클러스터 환경을 제공"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF3fXBZwnZ5g"
      },
      "source": [
        "# 2. 빅데이터 양대 산맥: Hadoop과 Spark\n",
        "\n",
        "- 하둡: Java 기반\n",
        "- 스파크: Java, Scala 기반"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aqxuns4nyO6"
      },
      "source": [
        "### 2.1 하둡 에코시스템\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/80008411/144402848-6f9f2d6f-c364-4ae9-8f37-2af3ebf2234d.png)\n",
        "\n",
        "1. 데이터 수집(Data Ingestion)\n",
        "- 스쿱(Sqoop): RDBMS(오라클, MySQL 등)와 하둡 사이의 데이터를 이동\n",
        "- 플럼(Flume): 분산 환경에서 대량의 로그 데이터를 효과적으로 수집해 합친 후 다른 곳으로 전송\n",
        "\n",
        "2. 데이터 처리(Data Preprocessing)\n",
        "- 하둡 분산 파일 시스템\n",
        "- 맵리듀스\n",
        "- 얀(Yarn): 하둡 클러스터의 리소스 관리\n",
        "- 스파크: In-memory 기반 클러스터링 컴퓨팅 데이터 처리\n",
        "    - 스파크 코어, 스파크 SQL, MLlib, GraphX 등의 컴포넌트로 구성\n",
        "\n",
        "3. 데이터 분석(Data Analysis)\n",
        "- 피그(Pig): 맵리듀스로 실행하기 어려운 데이터 관련 작업, filter, join, query 등 작업 실행\n",
        "- 임팔라(Impala): 고성능 SQL 엔진\n",
        "- 하이브(Hive): 임팔라와 유사한 SQL 관련 기능 제공\n",
        "\n",
        "4. 데이터 검색(Data Exploration)\n",
        "- 클라우데라 서(Cloudera Search): real-time으로 데이터에 검색이 가능\n",
        "- 휴(Hue): 웹 인터페이스 제공\n",
        "\n",
        "5. 기타\n",
        "- 우지(Oozie): 워크플로우 관리, Job 스케쥴러\n",
        "- HBase: NOSQL 기반으로 HDFS에 의해 처리된 데이터 처장\n",
        "- 제플린(Zeppelin): 데이터 시각화\n",
        "- SparkMLlib, 머하웃(mahout): 머신러닝 관련 라이브러리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwfABxhmrIAG"
      },
      "source": [
        "## 2.2 스파크 에코시스템\n",
        "\n",
        "- 하둡과 완전히 별개로 존재하는 게 아니라, 하둡 기반의 빅데이터 생태계를 이루는 주요 컴포넌트로서 존재\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/80008411/144404056-46f595bb-662d-4e27-b0b8-61cf00c5efc5.png)\n",
        "\n",
        "- 리소스 관리(주로 클러스터 관리)는 하둡의 yarn 또는 Mesos를 사용하거나, 스파크 자체 관리 기능을 그대로 사용\n",
        "- 데이터 저장은 Local FS나 하둡의 HDFS, 또는 AWS의 S3 인스턴스를 이용. 기존 RDBMS나 NoSQL을 이용하기도 함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UYUatcjrcsP"
      },
      "source": [
        "## 2.3 하둡 VS. 스파크\n",
        "\n",
        "- [영상](https://youtu.be/xDpvyu0w0C8)\n",
        "- 스파크의 in-memory 기반 데이터 처리 방식으로 인해 하둡과 비교해 더 빠르게 처리할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t9_NAUYtifI"
      },
      "source": [
        "# Spark 데이터 처리 방식: RDD\n",
        "\n",
        "- 스파크는 RDD를 구현하기 위한 프로그램\n",
        "- RDD를 스파크라는 프로그램으로 실행함으로써 메모리 기반의 대량 데이터 연산이 가능(하둡보다 100배 빠른 연산 가능)\n",
        "\n",
        "1. 등장 배경\n",
        "\n",
        "- 하둡과 스파크 기반 데이터 처리 방법 비교\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/80008411/144405967-3841b863-e80c-4ba7-9d4d-d55edba4e64f.png)\n",
        "\n",
        "- 하둡은 파일을 디스크에 저장한 뒤, 그걸 불러와서 연산하고 다시 디스크에 저장\n",
        "- 모든 연산마다 디스크에서 파일을 읽고 쓰는 데 시간이 오래 걸림\n",
        "- 즉 I/O 바운드가 하둡의 주요 병목 현상\n",
        "- 스파크는 하드디스크에서 파일을 읽어온 뒤 연산 단계에서는 데이터를 메모리에 저장\n",
        "- 그런데 메모리는 휘발성이므로 메모리에 적재하기 좋은 형태로 추상화 작업이 필요\n",
        "- 즉 RDD는 스파크의 기본 추상 개념으로, 클러스터의 머신(노드)의 여러 메모리에 분산 저장할 수 있는 데이터 집합을 의미"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "powge73Bfd0I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdrHXZ9EkeVe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}